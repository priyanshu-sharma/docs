Job Description:

 

We are seeking a highly experienced and certified Data Lead with extensive knowledge of Google Cloud Platform (GCP) to join our dynamic team. As a Data Lead, you will play a pivotal role in shaping our data architecture, ensuring its scalability, performance, and security to support our organization's data-driven initiatives.

 

Key Responsibilities:


Architectural Design: Collaborate with cross-functional teams to design and develop data architectures, ensuring they meet the organization's strategic goals, scalability, and performance requirements.
GCP Expertise: Leverage your deep understanding of Google Cloud Platform, including GCP services like BigQuery, Dataflow, Dataprep, and Pub/Sub, to create data solutions tailored to our business needs. Experience in all the Cloud Data Streams, Data Ingestion, Pipelines required.
Data Governance: Implement data governance best practices and policies to ensure data quality, security, and compliance with relevant regulations.

Troubleshooting: Act as a subject matter expert in resolving data-related issues and providing timely solutions.

 

Qualifications:


Minimum 10+ years of experience in data architecture.
Certified in Google Cloud Platform (GCP), demonstrating proficiency in GCP services.
Proven experience in architecting and implementing data solutions in a cloud environment.
Excellent communication and interpersonal skills for collaboration with cross-functional teams.
Leadership skills to mentor and lead data engineering teams.

Prior pharma or healthcare industry experience required.

Proven ability to lead the team and manage project.

Education:
Bachelors Degree in Computer Science or Engineering
Masters Degree in Computer Science Preferred

###################################

Job Title:  Data Engineer
Location: West Windsor, NJ ( Onsite)
Duration ; Contract
Job Description: We are seeking a highly skilled and motivated Data Engineer to join our clinical operations data team. As a Data Engineer, you will be primarily responsible for designing and developing data transformations and data models to ensure reliable and efficient data processing and analysis. You will work closely with cross-functional teams to support data-driven decision-making processes and contribute to the overall success of our insights teams.

Key Responsibilities:

Data Modeling and Development:
Design and implement robust data models using DBT.
Write and maintain data models, tests, and macros to ensure data quality and integrity.
Database Management:
Optimize queries and models for Snowflake to ensure high performance and scalability.
Debug and troubleshoot slow-performing queries to improve overall system efficiency.
Development Best Practices:
Adhere to and promote development best practices, including version control using Git and branching models.
Code review to ensure consistent coding standards and practices.
Collaboration and Communication:
Utilize collaboration tools like Jira and Confluence to document processes, track tasks, and share knowledge.
Participate in scrum methodology, including daily stand-ups, sprint planning, and retrospectives.
Communicate effectively with team members and stakeholders to understand requirements and provide updates.
Independent Work and Problem-Solving:
Take ownership of assigned tasks and work independently to complete them.
Proactively seek help and clarification when needed to ensure task completion.
Continuously improve and innovate data processes to enhance overall efficiency and effectiveness.
Quality Assurance:
Maintain a high drive for quality in all data engineering tasks.
Ensure all data transformations and models adhere to rigorous quality standards.
Qualifications:

Proficient in SQL with a strong understanding of database concepts and optimization techniques.
Proficient in DBT with experience in writing models, tests, and macros.
Good knowledge of Snowflake, including query optimization and troubleshooting.
Familiarity with development best practices, version control (Git), and branching models.
Experience with collaboration tools like Jira and Confluence.
Comfortable working in a scrum methodology and participating in agile ceremonies.
Strong problem-solving skills and ability to work independently.
Excellent communication and collaboration skills.
High drive for quality and attention to detail in data engineering tasks.
Preferred Qualifications:

Bachelor's degree in Computer Science, Information Technology, or a related field.
Experience in data engineering or a related role.
Familiarity with cloud-based data platforms and services.
Domain knowledge of clinical operational data and the pharmaceutical industry.
Proficiency in Python and Airflow for data engineering and automation tasks.